{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple code to train a neural network from scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a \"Sigmoid\". This is the activation of a neuron.\n",
    "# A function that will map any value to a value bettween 0 and 1\n",
    "# Creates probabilities out of numbers\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return (x*(1-x))\n",
    "    return (1/(1+np.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting in the Sigmoid:\n",
    "![sigmoid](img/sigmoid.png)\n",
    "A perceptron classifier is a simple model of a neuron. It has different inputs (x1...xn) with different weights (w1...wn).\n",
    "image\n",
    "The weighted sum s of these inputs is then passed through a step function f (usually a Heaviside step function).\n",
    "\n",
    "![perceptron](img/perceptron.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the dataset as a matrix with input Data:\n",
    "# Each row is a diferent training example\n",
    "# Each column represents a diferent neuron \n",
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output Data with one output neuron each\n",
    "Y = np.array([[1],\n",
    "              [0.7],\n",
    "              [3],\n",
    "              [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed them to make them deterministic\n",
    "# give random numbers with the same starting point (useful for debuging)\n",
    "# so we can get the same sequence of generated numbers everytime we run the program\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create synapse matrices.\n",
    "# Initialize the weights of a neural network\n",
    "# (it is a neural network with two layers of weights):\n",
    "syn0 = 2 * np.random.random((3, 4)) - 1\n",
    "syn1 = 2 * np.random.random((4, 1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.934545246367\n",
      "Error:0.502784580514\n",
      "Error:0.501866999994\n",
      "Error:0.501483292108\n",
      "Error:0.501261879281\n",
      "Error:0.501114122775\n",
      "Output after\n",
      "[[ 0.99999979]\n",
      " [ 0.69998478]\n",
      " [ 0.99999684]\n",
      " [ 0.00400894]]\n",
      "Objective\n",
      "[[ 1. ]\n",
      " [ 0.7]\n",
      " [ 3. ]\n",
      " [ 0. ]]\n"
     ]
    }
   ],
   "source": [
    "# Training code (loop)\n",
    "for j in xrange(60000):\n",
    "    # optimize the network for the given data set\n",
    "    # First layer it's just our input data\n",
    "    l0 = X\n",
    "    # Prediction step\n",
    "    # preform matrix multiplication bettween each layer and its synapse\n",
    "    # Then run sigmoid function on the matrix to create the next layer\n",
    "    l1 = nonlin(np.dot(l0, syn0))\n",
    "    l2 = nonlin(np.dot(l1, syn1))\n",
    "    \n",
    "    # With the above prediction of the output in l2 we can compare it to the expected \n",
    "    # output data using subtraction to get an error rate\n",
    "    l2_error = Y - l2\n",
    "    \n",
    "    # Print the average error at a set interval to make sure it goes down every time\n",
    "    if(j % 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(l2_error)))\n",
    "        \n",
    "    # Multiply the error rate by the slope of the sigmoid at the values in l2\n",
    "    l2_delta = l2_error * nonlin(l2, deriv=True)\n",
    "    \n",
    "    # (Backpropagation) How much did l1 contributed to the error on l2 ?\n",
    "    # Multiply layer 2 delta by synapse 1 transpose.\n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    # Get l1's delta by multlying it's error by the result of the sigmoid function\n",
    "    l1_delta = l1_error * nonlin(l1, deriv=True)\n",
    "    \n",
    "    # (Gradient Descent) update weights \n",
    "    # Now that we have deltas for each of our layers, we can use them to update\n",
    "    # our synapses rates to reduce the error rate more and more every iteration.\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "    \n",
    "print \"Output after\"\n",
    "print l2\n",
    "print \"Objective\"\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999979]\n",
      " [ 0.69998478]\n",
      " [ 0.99999684]\n",
      " [ 0.00400894]]\n"
     ]
    }
   ],
   "source": [
    "print l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next demo: \n",
    "http://localhost:8888/notebooks/final/sklearn_demo_Server_Health.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
